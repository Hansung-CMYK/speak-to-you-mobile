import 'dart:async';
import 'dart:collection';
import 'dart:convert';
import 'dart:typed_data';

import 'package:ego/services/chat/chat_room_service.dart';
import 'package:ego/services/setting_service.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
import 'package:audioplayers/audioplayers.dart';

class VoiceChatSocketClient {
  final String userId;
  final int egoId;
  final String speaker;
  final void Function(Map<String, dynamic>) onMessage;
  final void Function(Uint8List) onAudioChunk;

  late WebSocketChannel _channel;
  bool _isConnected = false;

  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final AudioPlayer _player = AudioPlayer();
  late StreamController<Uint8List> _streamController;

  final Queue<Uint8List> _audioQueue = Queue(); // ìˆ˜ì‹ ëœ ìŒì„± ì¬ìƒ í
  bool _isPlaying = false; // í˜„ì¬ ì¬ìƒ ì¤‘ ì—¬ë¶€

  VoiceChatSocketClient({
    required this.userId,
    required this.egoId,
    required this.speaker,
    required this.onMessage,
    required this.onAudioChunk,
  });

  bool _isMicOn = true;

  Future<void> toggleMic() async {
    _isMicOn = !_isMicOn;
    print(_isMicOn ? "ğŸ™ï¸ ë§ˆì´í¬ ON (ì „ì†¡ í—ˆìš©)" : "ğŸ”‡ ë§ˆì´í¬ OFF (ì „ì†¡ ì°¨ë‹¨)");
  }

  bool get isMicOn => _isMicOn;

  Future<void> connect() async {
    final chatRoomId = await ChatRoomService.fetchChatRoomIdByEgoIdNuserId(userId, egoId);
    final url = '${SettingsService().webVoiceUrl}/voice-chat?user_id=$userId&ego_id=$egoId&spk=$speaker&chat_room_id=$chatRoomId';

    _channel = WebSocketChannel.connect(Uri.parse(url));
    _channel.stream.listen(
          (data) {
        try {
          if (data is String) {
            final parsed = jsonDecode(data);
            print("ğŸ“¥ [JSON ìˆ˜ì‹ ] $parsed");

            if (parsed['type'] == 'audio_chunk' && parsed['audio_base64'] != null) {
              final base64Str = parsed['audio_base64'];
              final bytes = base64Decode(base64Str);
              print("ğŸ§ base64 ë””ì½”ë”© ì™„ë£Œ: ${bytes.length} bytes");

              onAudioChunk(bytes);
              _enqueueAudio(bytes);
            } else {
              onMessage(parsed);
            }
          } else if (data is List<int>) {
            final bytes = Uint8List.fromList(data);
            print("ğŸ“¥ [Binary ìˆ˜ì‹ ] ${bytes.length} bytes");

            final sample = bytes.take(10).map((b) => b.toRadixString(16).padLeft(2, '0')).join(' ');
            print("ğŸ§ª ìˆ˜ì‹  ë°”ì´ë„ˆë¦¬ ìƒ˜í”Œ (ì• 10ë°”ì´íŠ¸): $sample");

            onAudioChunk(bytes);
            _enqueueAudio(bytes);
          }
        } catch (e, stack) {
          print("âš ï¸ ìˆ˜ì‹  ì²˜ë¦¬ ì—ëŸ¬: $e");
          print(stack);
        }
      },
      onDone: () {
        _isConnected = false;
        print("âŒ WebSocket ëŠê¹€, ì¬ì—°ê²° ì‹œë„ ì¤‘...");
        Future.delayed(const Duration(seconds: 2), connect);
      },
      onError: (err) {
        _isConnected = false;
        print("ğŸ›‘ WebSocket ì—ëŸ¬: $err");
      },
    );

    _isConnected = true;
    print("âœ… WebSocket ì—°ê²°ë¨");

    await _startMicStream();
  }

  Future<void> _startMicStream() async {
    final micPermission = await Permission.microphone.request();
    if (!micPermission.isGranted) {
      print("âŒ ë§ˆì´í¬ ê¶Œí•œ ì—†ìŒ");
      return;
    }

    _streamController = StreamController<Uint8List>();
    _streamController.stream.listen((pcmBytes) {
      // ë‚´ê°€ ë§í•˜ë©´ ìƒëŒ€ë°© ìŒì„± ì¤‘ì§€ ë° í ì‚­ì œ
      clearAudioQueueAndStopPlayback();
      sendPCM(pcmBytes, 16000);
    });

    await _recorder.openRecorder();
    await _recorder.startRecorder(
      codec: Codec.pcm16,
      sampleRate: 16000,
      numChannels: 1,
      bitRate: 256000,
      toStream: _streamController.sink,
    );

    print("ğŸ™ï¸ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ë¨");
  }

  void sendPCM(Uint8List pcmBytes, int sampleRate) {
    if (!_isConnected || !_isMicOn) return;

    final meta = jsonEncode({'sampleRate': sampleRate});
    final metaBytes = utf8.encode(meta);
    final metaLength = metaBytes.length;

    final buffer = BytesBuilder();
    final header = ByteData(4)..setUint32(0, metaLength, Endian.little);
    buffer.add(header.buffer.asUint8List());
    buffer.add(metaBytes);
    buffer.add(pcmBytes);

    _channel.sink.add(buffer.toBytes());
  }

  void _enqueueAudio(Uint8List bytes) {
    if (_isMicOn) {
      // ë‚´ê°€ ë§í•˜ëŠ” ì¤‘ì´ë©´ ìˆ˜ì‹  ìŒì„± ë¬´ì‹œ
      print("ğŸ›‘ ìˆ˜ì‹  ì˜¤ë””ì˜¤ ë¬´ì‹œ: ë§ˆì´í¬ ON ìƒíƒœ");
      return;
    }

    _audioQueue.addLast(bytes);
    if (!_isPlaying) {
      _processAudioQueue();
    }
  }

  Future<void> _processAudioQueue() async {
    _isPlaying = true;

    while (_audioQueue.isNotEmpty && !_isMicOn) {
      final bytes = _audioQueue.removeFirst();
      print("ğŸ§ íì—ì„œ ì¬ìƒ: ${bytes.length} bytes");

      try {
        await _player.play(BytesSource(bytes));
        await _player.onPlayerComplete.first;
      } catch (e) {
        print("âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: $e");
      }
    }

    _isPlaying = false;
  }

  void clearAudioQueueAndStopPlayback() async {
    _audioQueue.clear();

    try {
      await _player.stop();
      print("ğŸ›‘ ìˆ˜ì‹  ìŒì„± ì¬ìƒ ì¤‘ì§€ ë° í ë¹„ì›€ ì™„ë£Œ");
    } catch (e) {
      print("âš ï¸ ì¬ìƒ ì¤‘ì§€ ì‹¤íŒ¨: $e");
    }

    _isPlaying = false;
  }

  void stopAudio() async {
    try {
      await _player.stop();
      print("ğŸ›‘ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ ì™„ë£Œ");
    } catch (e) {
      print("âš ï¸ ì˜¤ë””ì˜¤ ì¤‘ì§€ ì‹¤íŒ¨: $e");
    }
  }

  Future<void> stop() async {
    await _recorder.stopRecorder();
    await _recorder.closeRecorder();
    await _streamController.close();
    await _player.dispose();
    _channel.sink.close();
  }
}