import 'dart:async';
import 'dart:convert';
import 'dart:collection';
import 'dart:typed_data';

import 'package:ego/services/chat/chat_room_service.dart';
import 'package:ego/services/setting_service.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
import 'package:audioplayers/audioplayers.dart';

const int kFlushBytes = 3200; // 0.1 s @16 kHz (PCM16 mono)

class VoiceChatSocketClient {
  final String userId;
  final int egoId;
  final String speaker;
  final void Function(Map<String, dynamic>) onMessage;
  final void Function(Uint8List) onAudioChunk;

  late WebSocketChannel _channel;
  bool _isConnected = false;

  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final AudioPlayer _player = AudioPlayer();
  late StreamController<Uint8List> _streamController;

  bool _isMicOn = true;

  // ğŸ”Š ìˆœì„œëŒ€ë¡œ ì¬ìƒí•  ì˜¤ë””ì˜¤ í
  final Queue<Uint8List> _audioQueue = Queue<Uint8List>();
  bool _isPlaying = false;

  VoiceChatSocketClient({
    required this.userId,
    required this.egoId,
    required this.speaker,
    required this.onMessage,
    required this.onAudioChunk,
  });

  bool get isMicOn => _isMicOn;

  /// ë§ˆì´í¬ í† ê¸€ (OFF ì‹œ EOS ì „ì†¡)
  Future<void> toggleMic() async {
    _isMicOn = !_isMicOn;
    print(_isMicOn ? "ğŸ™ï¸ ë§ˆì´í¬ ON" : "ğŸ”‡ ë§ˆì´í¬ OFF");
    if (!_isMicOn) {
      sendEos();
    } else {
      await _startMicStream();
    }
  }

  /// WebSocket ì—°ê²° ë° ìŠ¤íŠ¸ë¦¼ ë¦¬ìŠ¤ë„ˆ
  Future<void> connect() async {
    final chatRoomId =
    await ChatRoomService.fetchChatRoomIdByEgoIdNuserId(userId, egoId);
    final url =
        '${SettingsService().webVoiceUrl}/voice-chat?user_id=$userId&ego_id=$egoId&spk=$speaker&chat_room_id=$chatRoomId';

    _channel = WebSocketChannel.connect(Uri.parse(url));
    _isConnected = true;
    print("âœ… WebSocket ì—°ê²°ë¨");

    _channel.stream.listen(
          (data) {
        try {
          if (data is String) {
            final parsed = jsonDecode(data);
            final type = parsed['type'];
            switch (type) {
              case 'audio_chunk':
                final base64Str = parsed['audio_base64'] as String?;
                if (base64Str != null) {
                  final bytes = base64Decode(base64Str);
                  onAudioChunk(bytes);
                  _enqueueAudio(bytes);
                }
                break;
              case 'cancel_audio':
                stopAudio();
                break;
              default:
                onMessage(parsed);
            }
          } else if (data is List<int>) {
            final bytes = Uint8List.fromList(data);
            onAudioChunk(bytes);
            _enqueueAudio(bytes);
          }
        } catch (e, st) {
          print("âš ï¸ ìˆ˜ì‹  ì²˜ë¦¬ ì—ëŸ¬: $e\n$st");
        }
      },
      onDone: () {
        _isConnected = false;
        print("âŒ WebSocket ëŠê¹€, ì¬ì—°ê²° ì‹œë„ ì¤‘...");
        Future.delayed(const Duration(seconds: 2), connect);
      },
      onError: (err) {
        _isConnected = false;
        print("ğŸ›‘ WebSocket ì—ëŸ¬: $err");
      },
    );

    await _startMicStream();
  }

  /// ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
  Future<void> _startMicStream() async {
    final micPermission = await Permission.microphone.request();
    if (!micPermission.isGranted) {
      print("âŒ ë§ˆì´í¬ ê¶Œí•œ ì—†ìŒ");
      return;
    }

    _streamController = StreamController<Uint8List>();
    _streamController.stream.listen((pcmBytes) {
      sendPCM(pcmBytes, 16000);
    });

    await _recorder.openRecorder();
    await _recorder.startRecorder(
      codec: Codec.pcm16,
      sampleRate: 16000,
      numChannels: 1,
      bitRate: 256000,
      toStream: _streamController.sink,
    );

    print("ğŸ™ï¸ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ë¨");
  }

  /// PCM ì „ì†¡
  void sendPCM(Uint8List pcmBytes, int sampleRate) {
    if (!_isConnected || !_isMicOn) return;
    final meta = jsonEncode({'sampleRate': sampleRate});
    final metaBytes = utf8.encode(meta);
    final header = ByteData(4)..setUint32(0, metaBytes.length, Endian.little);
    final buf = BytesBuilder()
      ..add(header.buffer.asUint8List())
      ..add(metaBytes)
      ..add(pcmBytes);
    _channel.sink.add(buf.toBytes());
  }

  /// EOS(end-of-speech) ì „ì†¡
  void sendEos() {
    if (!_isConnected) return;
    _channel.sink.add(jsonEncode({'eos': true}));
    print("ğŸ“¤ EOS ì „ì†¡");
  }

  /// ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ íì— ë„£ê³  ì¬ìƒ ì‹œë„
  void _enqueueAudio(Uint8List bytes) {
    _audioQueue.add(bytes);
    _playNext();
  }

  /// íì— ë‚¨ì€ ë‹¤ìŒ ì²­í¬ë¥¼ ì¬ìƒ
  void _playNext() {
    if (_isPlaying || _audioQueue.isEmpty) return;
    final bytes = _audioQueue.removeFirst();
    _isPlaying = true;
    _player.play(BytesSource(bytes)).then((_) {
      _isPlaying = false;
      _playNext();
    }).catchError((e) {
      print("âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: $e");
      _isPlaying = false;
    });
  }

  /// ì¬ìƒ ì¤‘ì§€: í”Œë ˆì´ì–´ ë©ˆì¶”ê³  í ì´ˆê¸°í™”
  Future<void> stopAudio() async {
    try {
      await _player.stop();
      _audioQueue.clear();
      _isPlaying = false;
      print("ğŸ›‘ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ ë° ë²„í¼ ì´ˆê¸°í™”");
    } catch (e) {
      print("âš ï¸ stopAudio ì‹¤íŒ¨: $e");
    }
  }

  /// ì „ì²´ ì—°ê²° í•´ì œ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  Future<void> stop() async {
    await _recorder.stopRecorder();
    await _recorder.closeRecorder();
    await _streamController.close();
    await _player.dispose();
    _channel.sink.close();
    print("ğŸ§¹ ì „ì²´ ì¢…ë£Œ ì™„ë£Œ");
  }
}